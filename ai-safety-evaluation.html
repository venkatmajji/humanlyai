<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>AI Safety Evaluation | HumanlyAI — Safe, Borderline, Unsafe Scoring</title>
  <meta name="description" content="HumanlyAI provides AI safety evaluation for GenAI: Safe/Borderline/Unsafe scoring, hallucination flags, refusal quality checks, and structured reporting." />
  <meta name="robots" content="index,follow" />
  <link rel="canonical" href="https://humanlyai.us/ai-safety-evaluation.html" />

  <!-- Open Graph -->
  <meta property="og:title" content="AI Safety Evaluation | HumanlyAI" />
  <meta property="og:description" content="Safety evaluation for GenAI: Safe/Borderline/Unsafe scoring, hallucination detection, red-team style risk finding, and structured reporting." />
  <meta property="og:type" content="website" />
  <meta property="og:url" content="https://humanlyai.us/ai-safety-evaluation.html" />
  <meta property="og:image" content="https://humanlyai.us/og-image.png" />

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="AI Safety Evaluation | HumanlyAI" />
  <meta name="twitter:description" content="Safety evaluation for GenAI: Safe/Borderline/Unsafe scoring, hallucination detection, refusal quality checks, and structured reporting." />
  <meta name="twitter:image" content="https://humanlyai.us/og-image.png" />

  <style>
    :root{
      --bg:#0E0E12; --card:#14141B; --text:#FFFFFF; --muted:#9A9DAA; --accent:#5CF2FF;
      --border: rgba(154,157,170,.22);
    }
    *{box-sizing:border-box}
    body{margin:0;font-family:Inter,system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif;background:var(--bg);color:var(--text);line-height:1.6}
    a{color:var(--accent);text-decoration:none}
    a:hover{text-decoration:underline}
    .container{max-width:1100px;margin:0 auto;padding:24px}
    .nav{display:flex;align-items:center;justify-content:space-between;padding:8px 0;gap:12px;flex-wrap:wrap}
    .logo{display:flex;gap:10px;align-items:center;font-weight:700}
    .logo img{height:32px;width:auto;display:block}
    .badge{font-size:12px;color:var(--muted);border:1px solid var(--border);padding:4px 10px;border-radius:999px}
    .btn{display:inline-flex;align-items:center;justify-content:center;gap:8px;padding:10px 14px;border-radius:12px;border:1px solid var(--border);background:transparent;color:var(--text);cursor:pointer}
    .btn.primary{background:var(--accent);color:#001014;border-color:transparent;font-weight:700}
    .btn:hover{opacity:.92}
    .hero{padding:30px 0 10px;display:grid;grid-template-columns:1.25fr .75fr;gap:16px;align-items:start}
    h1{font-size:40px;line-height:1.12;margin:0 0 10px}
    h2{font-size:24px;margin:0 0 10px}
    p{margin:0 0 12px;color:var(--muted)}
    .card{background:var(--card);border:1px solid var(--border);border-radius:18px;padding:18px}
    .grid2{display:grid;grid-template-columns:repeat(2,1fr);gap:14px}
    .grid3{display:grid;grid-template-columns:repeat(3,1fr);gap:14px}
    ul{margin:8px 0 0 20px;color:var(--muted)}
    li{margin:6px 0}
    .divider{height:1px;background:var(--border);margin:18px 0}
    .kicker{color:var(--accent);font-weight:700;letter-spacing:.12em;text-transform:uppercase;font-size:12px;margin:0 0 10px}
    .tag{font-size:12px;border:1px solid var(--border);color:var(--muted);padding:6px 10px;border-radius:999px}
    .pill{display:flex;gap:8px;flex-wrap:wrap}
    .foot{padding:26px 0;color:var(--muted);font-size:13px}
    @media (max-width:900px){
      .hero{grid-template-columns:1fr}
      .grid2,.grid3{grid-template-columns:1fr}
      h1{font-size:34px}
    }
  </style>

  <!-- FAQ Schema: AI Safety Evaluation -->
  <script type="application/ld+json">
  {
    "@context":"https://schema.org",
    "@type":"FAQPage",
    "mainEntity":[
      {
        "@type":"Question",
        "name":"What is AI safety evaluation?",
        "acceptedAnswer":{
          "@type":"Answer",
          "text":"AI safety evaluation is the process of assessing model outputs for user harm risk, policy violations, unsafe guidance, and reliability issues such as hallucinations and overconfidence."
        }
      },
      {
        "@type":"Question",
        "name":"How does HumanlyAI score safety?",
        "acceptedAnswer":{
          "@type":"Answer",
          "text":"HumanlyAI uses a structured rubric that classifies outputs as Safe, Borderline, or Unsafe, and can include separate scoring for hallucinations, factual accuracy, tone, and overall quality."
        }
      },
      {
        "@type":"Question",
        "name":"Do you test hallucinations and factual accuracy as part of safety evaluation?",
        "acceptedAnswer":{
          "@type":"Answer",
          "text":"Yes. Safety evaluation can include hallucination flags, factual accuracy scoring, and overconfidence detection, especially for high-stakes domains."
        }
      },
      {
        "@type":"Question",
        "name":"What do we need to provide to start safety evaluation?",
        "acceptedAnswer":{
          "@type":"Answer",
          "text":"Clients typically provide prompts and model outputs, target policies or constraints, and the intended user context. HumanlyAI provides rubrics, trained evaluators, QA, and structured reporting."
        }
      },
      {
        "@type":"Question",
        "name":"How quickly can you run a safety pilot?",
        "acceptedAnswer":{
          "@type":"Answer",
          "text":"Pilot timelines depend on volume and QA depth, but many pilots can be completed within 7–14 days once scope and rubrics are aligned."
        }
      }
    ]
  }
  </script>
</head>

<body>
  <header class="container">
    <div class="nav">
      <a class="logo" href="/" aria-label="HumanlyAI Home">
        <img src="/logo.png" alt="HumanlyAI logo" />
        <span class="badge">AI Safety Evaluation</span>
      </a>
      <div style="display:flex;gap:10px;flex-wrap:wrap">
        <a class="btn" href="/">Home</a>
        <a class="btn" href="/blog/">Blog</a>
        <a class="btn primary" href="#contact">Request a Pilot</a>
      </div>
    </div>
  </header>

  <main class="container">
    <section class="hero">
      <div>
        <p class="kicker">Safety-first human evaluation</p>
        <h1>AI Safety Evaluation for GenAI Systems</h1>
        <p>
          HumanlyAI helps teams identify unsafe, misleading, or non-compliant model behavior using
          <strong style="color:#fff">structured human judgment</strong> — including Safe/Borderline/Unsafe classification,
          hallucination flags, and defensible reporting.
        </p>
        <div class="pill" style="margin-top:10px">
          <span class="tag">Safe / Borderline / Unsafe</span>
          <span class="tag">Hallucination Flags</span>
          <span class="tag">Refusal Quality</span>
          <span class="tag">Structured Reporting</span>
        </div>
        <div style="display:flex;gap:12px;flex-wrap:wrap;margin-top:16px">
          <a class="btn primary" href="#contact">Request Safety Evaluation</a>
          <a class="btn" href="#how">See How It Works</a>
        </div>
        <p style="margin-top:10px;font-size:13px">
          Typical pilot turnaround: <strong style="color:#fff">7–14 days</strong> (scope dependent).
        </p>
      </div>

      <aside class="card">
        <p class="kicker">Best for</p>
        <p style="margin:0 0 10px;color:var(--muted)">
          Teams deploying copilots and assistants where unsafe guidance, hallucinations, or policy failures create reputational or compliance risk.
        </p>
        <div class="divider"></div>
        <p style="margin:0;color:var(--muted)">
          If users will rely on the output, you need a safety review process that is consistent and defensible.
        </p>
      </aside>
    </section>

    <section class="card" id="services" style="margin-top:14px">
      <p class="kicker">What we deliver</p>
      <div class="grid2" style="margin-top:10px">
        <div class="card">
          <h2 style="margin:0 0 6px">Safety Classification</h2>
          <p>Structured safety scoring for real user risk.</p>
          <ul>
            <li>Safe / Borderline / Unsafe</li>
            <li>User harm and misuse risk</li>
            <li>Policy compliance checks</li>
          </ul>
        </div>
        <div class="card">
          <h2 style="margin:0 0 6px">Hallucination & Accuracy</h2>
          <p>Reliability checks that catch false authority.</p>
          <ul>
            <li>Hallucination flagging</li>
            <li>Factual accuracy scoring</li>
            <li>Overconfidence detection</li>
          </ul>
        </div>
        <div class="card">
          <h2 style="margin:0 0 6px">Refusal Quality</h2>
          <p>When the model refuses, it must refuse well.</p>
          <ul>
            <li>Appropriate refusal behavior</li>
            <li>Safe alternatives where possible</li>
            <li>Non-evasive, non-harmful framing</li>
          </ul>
        </div>
        <div class="card">
          <h2 style="margin:0 0 6px">Reporting</h2>
          <p>Structured outputs you can track and act on.</p>
          <ul>
            <li>Score distributions and findings</li>
            <li>Examples of failure modes</li>
            <li>CSV/JSON delivery for internal use</li>
          </ul>
        </div>
      </div>
    </section>

    <section class="card" id="how" style="margin-top:18px">
      <p class="kicker">How it works</p>
      <h2>Safety evaluation workflow</h2>
      <div class="grid2" style="margin-top:12px">
        <div class="card">
          <p><strong>1) Scope & context</strong></p>
          <p>You share target use case, policies, and output samples.</p>
        </div>
        <div class="card">
          <p><strong>2) Rubrics & calibration</strong></p>
          <p>We align on definitions for safety and reliability scoring.</p>
        </div>
        <div class="card">
          <p><strong>3) Evaluate + QA</strong></p>
          <p>Evaluators score outputs; QA monitors agreement and edge cases.</p>
        </div>
        <div class="card">
          <p><strong>4) Deliver findings</strong></p>
          <p>We deliver structured results and examples of key failure modes.</p>
        </div>
      </div>
    </section>

    <section class="card" style="margin-top:18px">
      <p class="kicker">Why HumanlyAI</p>
      <h2>Defensible human judgment, consistently applied</h2>
      <div class="grid3" style="margin-top:12px">
        <div class="card">
          <p><strong>Trained evaluators</strong></p>
          <p>Certification + calibration so “safe” means the same thing every time.</p>
        </div>
        <div class="card">
          <p><strong>Safety-first bias</strong></p>
          <p>Conservative scoring when outputs could mislead or harm.</p>
        </div>
        <div class="card">
          <p><strong>Auditability</strong></p>
          <p>Gold tasks + QA review to support governance and reporting needs.</p>
        </div>
      </div>
    </section>

    <!-- Visible FAQ section (recommended to match schema) -->
    <section class="card" id="faq" style="margin-top:18px">
      <p class="kicker">FAQ</p>
      <h2>Common questions about AI safety evaluation</h2>
      <div class="grid2" style="margin-top:12px">
        <div class="card">
          <p><strong>What is AI safety evaluation?</strong></p>
          <p>Assessing model outputs for harm risk, unsafe guidance, policy failures, and reliability issues like hallucinations.</p>
        </div>
        <div class="card">
          <p><strong>How do you score safety?</strong></p>
          <p>We classify outputs as Safe, Borderline, or Unsafe, and can separately score hallucinations, accuracy, tone, and overall quality.</p>
        </div>
        <div class="card">
          <p><strong>What do we need to provide?</strong></p>
          <p>Prompts + outputs, target policies/constraints, and user context. We provide rubrics, trained evaluators, QA, and reporting.</p>
        </div>
        <div class="card">
          <p><strong>How fast can a pilot run?</strong></p>
          <p>Many pilots can complete in 7–14 days after scope and rubric alignment (volume dependent).</p>
        </div>
      </div>
    </section>

    <section class="card" id="contact" style="margin-top:18px">
      <p class="kicker">Contact</p>
      <h2>Request a safety pilot</h2>
      <p>Email us with your use case and evaluation goals. We’ll reply with a pilot scope.</p>
      <div style="display:flex;gap:12px;flex-wrap:wrap;margin-top:10px">
        <a class="btn primary"
           href="mailto:founder@humanlyai.us?subject=HumanlyAI%20Safety%20Evaluation%20Pilot%20Request&body=Hi%20HumanlyAI%2C%0A%0AUse%20case%3A%0ADomain%3A%0AEval%20needs%3A%20(Safety%2C%20hallucinations%2C%20refusal%20quality)%0AVolume%3A%0ATimeline%3A%0A%0AThanks%2C%0A">
          Email Founder
        </a>
        <a class="btn" href="/blog/">Read the Blog</a>
      </div>
    </section>

    <footer class="foot">
      <div class="divider"></div>
      <div style="display:flex;justify-content:space-between;gap:12px;flex-wrap:wrap">
        <div>© <span id="y"></span> HumanlyAI</div>
        <div>
          <a href="/privacy.html">Privacy</a> ·
          <a href="/terms.html">Terms</a>
        </div>
      </div>
    </footer>
  </main>

  <script>document.getElementById("y").textContent = new Date().getFullYear();</script>
</body>
</html>
